# Cell 1: Imports and Config
import os
import numpy as np
import joblib
from tqdm import tqdm
from sklearn.svm import SVC
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.metrics import accuracy_score, log_loss, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler  # === Added normalization ===
import matplotlib.pyplot as plt
import seaborn as sns

from torch.utils.tensorboard import SummaryWriter  

# === CONFIG ===

TRAIN_PATH = "/kaggle/input/grabmyo-5gestures-ml-features/GRABMyo_ML_Features/Train_Aggregated"
TEST_PATH  = "/kaggle/input/grabmyo-5gestures-ml-features/GRABMyo_ML_Features/Test_Aggregated"
CHECKPOINT_DIR = "/kaggle/working/grabmyo_checkpoints_svm"
os.makedirs(CHECKPOINT_DIR, exist_ok=True)
RESUME_PATH = os.path.join(CHECKPOINT_DIR, "best_model.pkl")
TRAIN_FROM_SCRATCH = False
PATIENCE = 5
VAL_SPLIT = 0.2
RANDOM_STATE = 42

# === TensorBoard writer ===
writer = SummaryWriter(log_dir='/kaggle/working/runs_svm')
# Cell 2: Load Data and Split
# === Load Data ===
X_train = np.load(os.path.join(TRAIN_PATH, "X.npy"))
y_train = np.load(os.path.join(TRAIN_PATH, "y.npy"))
X_test  = np.load(os.path.join(TEST_PATH, "X.npy"))
y_test  = np.load(os.path.join(TEST_PATH, "y.npy"))


# === Train/Val Split ===
X_tr, X_val, y_tr, y_val = train_test_split(
    X_train, y_train, test_size=VAL_SPLIT, stratify=y_train, random_state=RANDOM_STATE)
print(f"Train: {X_train.shape}, Test: {X_test.shape}, Validation:{X_val.shape}" )
print(f"Train: {y_train.shape}")
# Cell 3: Normalization
# === Added normalization ===
scaler = MinMaxScaler()
scaler.fit(X_tr)  # Fit scaler only on training data
X_tr_scaled = scaler.transform(X_tr)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)
print(f"Train: {X_tr_scaled.shape}, Test: {X_test_scaled.shape}, Validation:{X_val_scaled.shape}" )
# Cell 4: LDA Transformation
# === LDA ===
lda = LinearDiscriminantAnalysis()
X_tr_lda  = lda.fit_transform(X_tr_scaled, y_tr)   # Use scaled data here
X_val_lda = lda.transform(X_val_scaled)
X_test_lda = lda.transform(X_test_scaled)
print(f"Train: {X_tr_lda.shape}, Test: {X_test_lda.shape}, Validation:{X_val_lda.shape}" )
# Cell 5: Initialize Model and Resume if Possible
svm = SVC(kernel='rbf', probability=True)
best_val_acc = 0.0
best_val_loss = float('inf')
epochs_no_improve = 0
start_epoch = 0

# === Resume if available ===
if not TRAIN_FROM_SCRATCH and os.path.exists(RESUME_PATH):
    checkpoint = joblib.load(RESUME_PATH)
    svm = checkpoint['svm']
    lda = checkpoint['lda']
    scaler = checkpoint.get('scaler', scaler)   # Load scaler if saved, fallback to new scaler
    start_epoch = checkpoint['epoch'] + 1
    best_val_acc = checkpoint['best_val_acc']
    best_val_loss = checkpoint['best_val_loss']
    print(f" Resumed from epoch {start_epoch}")
else:
    print(" Starting training from scratch")
# Cell 6: Training Loop (1 Epoch Only)
print(f"\n Epoch 1")

svm.fit(X_tr_lda, y_tr)

val_preds = svm.predict(X_val_lda)
val_probs = svm.predict_proba(X_val_lda)
val_acc = accuracy_score(y_val, val_preds)
val_loss = log_loss(y_val, val_probs)

print(f" Val Acc: {val_acc:.4f} | Val Loss: {val_loss:.4f}")
writer.add_scalar("Accuracy/val", val_acc, 0)
writer.add_scalar("Loss/val", val_loss, 0)

# Save best model
if val_acc > best_val_acc:
    best_val_acc = val_acc
    joblib.dump({
        'epoch': 0,
        'svm': svm,
        'lda': lda,
        'scaler': scaler,  # Save scaler
        'best_val_acc': best_val_acc,
        'best_val_loss': best_val_loss
    }, RESUME_PATH)
    print(f" Saved best model at epoch 1 with Val Acc {val_acc:.4f}")

# Early stopping logic not needed with single epoch, but can be kept for logging
if val_loss < best_val_loss:
    best_val_loss = val_loss
    epochs_no_improve = 0
else:
    epochs_no_improve += 1

writer.add_scalar("Best_Val/Accuracy", best_val_acc, 0)
writer.close()
from sklearn.metrics import roc_auc_score, roc_curve, auc
from sklearn.preprocessing import label_binarize
import matplotlib.pyplot as plt
import numpy as np

# === Load Best Model ===
checkpoint = joblib.load(RESUME_PATH)
svm = checkpoint['svm']
lda = checkpoint['lda']
scaler = checkpoint.get('scaler', scaler)

# === Predict on Test Set ===
X_test_lda = lda.transform(X_test_scaled)
test_preds = svm.predict(X_test_lda)
test_probs = svm.predict_proba(X_test_lda)  # Needed for AUC-ROC

test_acc = accuracy_score(y_test, test_preds)
print(f" Final Test Accuracy: {test_acc:.4f}")

# === Classification Report ===
print(" Classification Report:")
print(classification_report(y_test, test_preds))

# === Confusion Matrix ===
cm = confusion_matrix(y_test, test_preds)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Test Confusion Matrix")
plt.show()

# === ROC-AUC Plot ===
# Binarize labels for multi-class AUC
classes = np.unique(y_test)
y_test_bin = label_binarize(y_test, classes=classes)

# Compute ROC curve and AUC for each class
plt.figure(figsize=(8,6))
for i in range(len(classes)):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], test_probs[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'Class {classes[i]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Multi-Class ROC Curve')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

